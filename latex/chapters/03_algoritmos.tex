\chapter{Descrição em Pseudocódigo dos Algoritmos da API}
\label{ch:pseudocode}

Neste capítulo, apresentaremos a descrição dos algoritmos, na forma
de pseudocódigos, que constam na especificação da API. Este capítulo
tem por objetivo preparar o leitor para ler e compreender com clareza
a implementação feita em Rust, trazendo descrições e explicações que
elucidem o funcionamento de cada algoritmo.

\section{Algoritmos de Árvore Geradora Mínima}

\subsection{Algoritmo de Kruskal}
\label{sec:pseudocode_kruskal}

O algoritmo de Kruskal, proposto por Joseph Kruskal em 1956, é um método
clássico e eficiente para construir a Árvore Geradora Mínima (AGM) de um
grafo ponderado. Seu funcionamento baseia-se em uma estratégia gulosa,
selecionando iterativamente as arestas de menor peso que não formem ciclos.

% tex-fmt: off
\begin{algorithm}
  \caption{Algoritmo de Kruskal}
  \begin{algorithmic}[0]
    \Require{$G := (V, A, c)$}
    \Ensure{Uma árvore geradora mínima $T \subseteq A$ tal que $c(T) \leq c(T\prime)$ para toda $T\prime \subseteq A$ que conecta $V$.}
    \Statex
    \Function{Kruskal}{$G$}
      \State{$T \gets \{\}$}
      \State{$\mathsf{componentes} \gets \{\}$}
      \For{$v \in V$}
        \State{$\mathsf{componentes} \gets \mathsf{componentes} \cup \{(v, \{v\})\}$}
      \EndFor
      \For{$(u, v) \in A$ ordenado por $c_{uv}$ crescente}
        \If{$\mathsf{encontrar}(u, \mathsf{componentes}) \neq \mathsf{encontrar}(v, \mathsf{componentes})$}
          \State{$T \gets T \cup \{(u, v)\}$}
          \State{$\mathsf{unir}(u, v, \mathsf{componentes})$}
        \EndIf
      \EndFor
      \State \Return $T$
    \EndFunction
  \end{algorithmic}
\end{algorithm}
\FloatBarrier
% tex-fmt: on

O algoritmo de Kruskal inicia-se ordenando todas as arestas do grafo
pelo seu peso. Em seguida, itera sobre essa lista ordenada, adicionando
as arestas à árvore geradora mínima sempre que isso não resultar na
formação de um ciclo.

\subsection{Algoritmo de Prim}
\label{sec:pseudocode_prim}

O algoritmo de Prim, desenvolvido por Robert C. Prim em 1957, é um
método clássico para construir a Árvore Geradora Mínima (AGM) de um
grafo ponderado e conexo. Assim como o algoritmo de Kruskal, utiliza
uma estratégia gulosa; entretanto, enquanto Kruskal seleciona arestas
globalmente pelo menor peso, Prim cresce a árvore gradualmente a
partir de um vértice inicial, sempre escolhendo a aresta de menor
custo que conecta a árvore parcial a um novo vértice. Quando
utilizado com estruturas como filas de prioridade, o algoritmo
alcança excelente desempenho em grafos densos.

% tex-fmt: off
\begin{algorithm}
  \caption{Algoritmo de Prim}
  \begin{algorithmic}[0]
    \Require{$G := (V, A, c)$, $r \in V$}
    \Ensure{Uma árvore geradora mínima $T \subseteq A$ tal que $c(T) \leq c(T\prime)$ para toda $T\prime \subseteq A$ que conecta $V$.}
    \Statex
    \Function{Prim}{$G, r$}
      \State{$T \gets \{\}$}
      \State{$\mathsf{visitado} \gets []$}
      \State{$\mathsf{visitado[r]} \gets 1$}
      \While{$\exists (u, v) \in A: u \in \mathsf{visitado} \land v \notin \mathsf{visitado}$}
        \State{$(u, v) \gets \min \{(u, v) \in A: u \in \mathsf{visitado} \land v \notin \mathsf{visitado}\}$}
        \State{$T \gets T \cup \{(u, v)\}$}
        \State{$\mathsf{visitado[v]} \gets 1$}
      \EndWhile
      \State \Return $T$
    \EndFunction
  \end{algorithmic}
\end{algorithm}
\FloatBarrier
% tex-fmt: on

Diferentemente do algoritmo de Kruskal, que começa com um conjunto vazio
de arestas, o algoritmo de Prim inicia-se a partir de um vértice escolhido
arbitariamente. A partir desse vértice, o algoritmo cresce a árvore
geradora mínima, adicionando a aresta de menor peso que conecta um
vértice da árvore a um vértice fora dela, até que todos os vértices
estejam incluídos na árvore.

\section{Algoritmos de Caminho Mais Curto}

\subsection{Algoritmo de Dijkstra}
\label{sec:pseudocode_dijkstra}
O algoritmo de \cite{dijkstraarticle}, proposto pelo cientista da
computação Edsger Dijkstra, é um algoritmo extremamente útil para
encontrar o caminho mais curto dentro de um grafo ponderado orientado
ou não orientado sem arestas negativas.

% tex-fmt: off
\begin{algorithm}
  \caption{Algoritmo de Dijkstra}
  \begin{algorithmic}[0]
    \Require{$G := (V, A, c)$, $v \in V$}
    \Ensure{Sequência de $v \in V$ ordenados que formam o caminho mais curto}
    \Statex
    \Function{Dijkstra}{$G, s$}
      \State{$\mathsf{predecessor} \gets []$}
      \State{$\mathsf{predecessor[s]} \gets \emptyset$}
      \State{$\mathsf{visitado} \gets []$}
      \State{$\mathsf{visitado[s]} \gets 1$}
      \State{$\mathsf{distancia} \gets []$}
      \State{$\mathsf{distancia[s]} \gets 0$}
      \For{$v \in V$}
        \If{$v \in \mathsf{vizinhos(v, G)}$}
          \State{$\mathsf{predecessor[v]} \gets s$}
          \State{$\mathsf{distancia[v]} \gets c_{sv}$}
        \Else
          \State{$\mathsf{predecessor[v]} \gets \emptyset$}
          \State{$\mathsf{distancia[v]} \gets \lim_{x \to +\infty}x$}
        \EndIf
      \EndFor
      \While{$u \in V \land \lnot \mathsf{visitado[u]}$}
        \State{$v \gets \min V$}
        \State{$\mathsf{visitado[v]} \gets 1$}
      \For{$n \in \mathsf{vizinhos(v, G)}$}
        \If{$n \not \in \mathsf{visitado} \land \mathsf{distancia[n]} > \mathsf{distancia[v]} + c_{vn}$}
          \State{$\mathsf{distancia[n]} \gets \mathsf{distancia[v]} + c_{vn}$}
          \State{$\mathsf{predecessor[n]} \gets v$}
          \EndIf
        \EndFor
      \EndWhile
      \State \Return{$(\mathsf{visitado, distancia})$}
    \EndFunction
  \end{algorithmic}
\end{algorithm}
\FloatBarrier
% tex-fmt: on

O algoritmo acima escolhe o vértice para operar com base no que tem a
menor distância alcançável. No início, ele visita o primeiro vértice
e determina a distância para os vizinhos como sendo o peso de suas
arestas; para os que não são alcançáveis, a distância é infinita.
Então, enquanto existirem vértices não visitados, o algortimo
seleciona o que tem a menor distância, o visita e então relaxa os
seus vizinhos: o relaxamento consiste em mudar o caminho no qual o
vizinho é visitado, caso isso melhore a distância até o vizinho. Isso
é feito verificando se a distância do vizinho é pior do que a
distância até o vértice atual + o peso da aresta que liga os dois. \\
Após o relaxamento, tudo se repete até que todos os vértices estejam
visitados. Então, ao final das iterações, teremos a menor rota de um
ponto de origem até todos os demais vértices.

\subsection{Algoritmo de Bellman-Ford}
\label{sec:pseudocode_bellmanford}
O algoritmo em questão surgiu durante a segunda metade da década da 50
através de publicações feitas num período de tempo muito próximo. Seu nome
homenageia os matemáticos americanos autores dos artigos que o conceberam,
\cite{bellmanaarticle} e \cite{fordarticle}. Esse se trata de um dos algoritmos
mais conhecidos dentro da Teoria dos Grafos, especialmente dentro do estudo de
dos problemas de caminho mínimo, e diferente de
\ref{sec:pseudocode_dijkstra}, não
se trata de um algoritmo guloso. Além de ter a capacidade de lidar
com arestas de
peso negativo e identificar ciclos negativos.

\begin{algorithm}
  \caption{Algoritmo de Bellman-Ford}
  \begin{algorithmic}[0]
    \Require{$G = (V, A, c)$, $v \in V$}
    \Ensure{Sequência de $v \in V$ ordenados que formam o caminho mais curto}
    \Statex
    \Function{Bellman-Ford}{G = (V, A, c), s}
    \State{$\mathsf{predecessor} \gets []$}
    \State{$\mathsf{distancia} \gets []$}
    \For{$v \in V$} \Comment{Inicialização}
    \State{$\mathsf{predecessor[v]} \gets \emptyset$}
    \State{$\mathsf{distancia[v]} \gets \infty$}
    \EndFor
    \State{$\mathsf{distancia[c]} \gets 0$}
    \For{$i \in [1,n)$}
    \For{$(u,v) \in A$} \Comment{Relaxamento de arestas}
    \If{$\mathsf{distancia[v]} > \mathsf{distancia[u]} + custo(u,v)$}
    \State{$\mathsf{distancia[v]} \gets \mathsf{distancia[u]} + + custo(u,v)$}
    \State{$\mathsf{predecessor[v]} \gets u$}
    \EndIf
    \EndFor
    \EndFor
    \State{$ciclo \gets falso$}
    \For{$(u,v) \in A$} \Comment{Verifica ciclo negativo}
    \If{$\mathsf{distancia[v]} > \mathsf{distancia[u]} + custo(u,v)$}
    \State{$ciclo \gets verdadeiro$}
    \EndIf
    \EndFor
    \State \Return{$(\mathsf{predecessor, distancia, ciclo})$}
    \EndFunction
  \end{algorithmic}
\end{algorithm}
\FloatBarrier

O algoritmo consiste em três partes: Inicialização, relaxamento de arestas e
verificação de ciclo negativos. A primeira etapa envolve percorrer todos os
vértices do grafo a fim de inicializar as variáveis de distância e predecessor.
A segunda diz respeito ao relaxamento de arestas, ou seja, usar a desigualdade
triangular para verificar se, dada uma aresta que liga os vértices A
e B, é possível
obter um custo menor de A para B percorrendo um terceiro vértice. E por fim, uma
vez realizado o relaxamento de arestas, a desigualdade triangular
será verificada
novamente para toda a aresta, pois caso inda seja possível diminuir o custo ao
percurrer alguma aresta do grafo há um ciclo negativo.

Note que este se trata de um algoritmo de complexidade $O(nm)$ em
essência. Entretanto,
a iteração a mais para verificar por ciclos negativos o faz ser $O(n{m}^2)$

\subsection{Algoritmo de Floyd-Warshall}
\label{sec:pseudocode_floyd-warshall}

O Algoritmo de Robert Floyd e Stephen Warshall, comumente chamado de
Floyd-Warshall \cite{floydwarshallWikipedia}, visa encontrar todos os
caminhos mais curtos entre todos os vértices de um grafo ponderado. O
algoritmo não detecta ciclos negativos, mas não é impedido por sua
existência, diferentemente de \ref{sec:pseudocode_dijkstra}.

A ideia geral do algoritmo é: para todos os vértices, adicionar o
vértice como intermediário no caminho entre outros dois se a distância
final entre as extremidades for menor. Em termos de pseudocódigo, o
algoritmo é descrito da seguinte forma:

% tex-fmt: off
\begin{algorithm}
  \caption{Algoritmo de Floyd-Warshall}
  \begin{algorithmic}[0]
    \Require{$G := (V, A, c)$}
    \Ensure{Um par $(D, P)$. Onde, para todo $i, j \in V$, $D := [d_{ij}]$
      e $d_{ij}$ representa a distância entre o vértices $i$ e $j$.
      $P := [p_{ij}]$ e $p_{ij}$ representa o vértice origem da última
    aresta no caminho de $i$ até $j$.}
    \Statex
    \Function{FloydWarshall}{G}
      \State{$D \gets \{d_{ij}\, |\, i, j \in V, d_{ij} := c_{ij} \text{ se }
          (i, j) \in A \text{ ou } d_{ij} := \lim_{x \to +\infty}x \text{
      caso contrário }   \}$}
      \State{$P \gets \{p_{ij}\, |\, (i, j) \in A, p_{ij} := i \}$}
      \For{$k \in V$}
        \For{$i \in V$}
          \For{$j \in V$}
            \If{$d_{ik} + d_{kj} < d_{ij}$}
              \State{$d_{ij} \gets d_{ik} + d_{kj}$}
              \State{$p_{ij} \gets p_{kj}$}
            \EndIf
          \EndFor
        \EndFor
      \EndFor
      \State \Return $(D, P)$
    \EndFunction
  \end{algorithmic}
\end{algorithm}
\FloatBarrier
% tex-fmt: on

O algoritmo primeiro começa inicializando a matriz de distâncias e
predecessores com os valores conhecidos entre os vértices adjacentes.
Após isso, o algoritmo, tenta inserir todo vértice $k$ no caminho
entre outros vértices $i$ e $j$ se for vantajoso, atualizando $D$ e
$P$ no processo.

\subsubsection{Árvore de caminhos mais curtos}

A partir do retorno do algoritmo de Floyd-Warshall, é possível
construir uma árvore tal que o caminho entre a raiz e qualquer
vértice, é exatamente o menor caminho entre os dois.

O algoritmo é recursivo, e a ideia geral é: para cada vértice final
de um caminho viável a partir de uma raiz, construir nó filho
recursivamente se o vértice predecessor do caminho entre a raiz
inicial (no caso base da recursão) e o vértice final for igual a raiz
atual (raiz corrente na recursão). O algoritmo pode ser descrito em
pseudocódigo da seguinte forma:

% tex-fmt: off
\begin{algorithm}
  \caption{Algoritmo de construção da árvore de caminhos mais curtos}
  \begin{algorithmic}[0]
    \Require{$G := (V, A, c)$, $r$ e $\mathcal{F}_\mathcal{W} := (D, P)$. Onde $\mathcal{F}_\mathcal{W}$ é o resultado
      da aplicação de Floyd-Warshall em $G$ e $r$, é a raiz escolhida previamente.}
      \Ensure{Uma árvore $\mathcal{A} := (n, \mathcal{F})$. Onde $n \in V$ e $\mathcal{F}$ é uma lista de árvores como $\mathcal{A}$.}
    \State
    \Function{ConstruirÁrvore}{$G, \mathcal{F}_\mathcal{W}, r, \mathcal{A} := (r, \mathcal{F} := \{\}), \Sigma := \{r\}$}
      \For{$j \in \{j\, |\, d_{ij} \in D, d_{ij} \neq \lim_{x \to +\infty}x\}$}
        \If{$j \neq n \land p_{rj} = n$}
          \If{$j \notin \Sigma$}
            \State{$\Sigma \gets \Sigma \cup \{j\}$}
            \State{$\mathcal{F} \gets \mathcal{F} \cup \{\mathsf{ConstruirÁrvore}(G, \mathcal{F}_\mathcal{W}, r, (j, \{\}), \Sigma)\}$}
          \EndIf
        \EndIf
      \EndFor
      \State \Return $\mathcal{A}$
    \EndFunction
  \end{algorithmic}
\end{algorithm}
% tex-fmt: on

Naturalmente, para recuperar o caminho mais curto entre $r$ e qualquer outro,
bastar percorrer a árvore.

\section{Algoritmos em Grafos Eulerianos}
\label{sec:pseudocode_hierholzer}

Os algoritmos apresentados nesta seção têm por objetivo determinar a
existência de Caminhos Eulerianos e Ciclos Eulerianos em grafos, além
de produzir explicitamente o caminho (quando existente). A fundamentação
teórica encontra-se no Capítulo 02, onde são
descritas as condições necessárias e suficientes para que um grafo seja
euleriano, tanto no caso orientado quanto não orientado.

O método utilizado para construir o caminho ou ciclo euleriano é o
\textbf{Algoritmo de Hierholzer}, originalmente proposto em 1736 e
considerado o procedimento padrão para percorrer todas as arestas de um
grafo exatamente uma vez.

\subsection{Algoritmo Principal de Hierholzer}

% tex-fmt: off
\begin{algorithm}[!ht]
\caption{Algoritmo de Hierholzer}
\begin{algorithmic}[1]
\Function{Hierholzer}{$G$, $\texttt{is\_directed}$}
    \State $\mathsf{outDegree}, \mathsf{inDegree} \gets$ \Call{CalcularGraus}{$G$, $\texttt{is\_directed}$}
    \State $(v_0, \mathsf{hasPath}, \mathsf{hasCycle}) \gets$ 
           \Call{VerificarCondicoesEulerianas}{$\mathsf{outDegree}, \mathsf{inDegree}, \texttt{is\_directed}$}
    
    \If{não $\mathsf{hasPath}$ e não $\mathsf{hasCycle}$}
        \State \Return $(\emptyset, \mathsf{falso}, \mathsf{falso})$
    \EndIf
    
    \If{$\mathsf{hasCycle}$ e $\mathsf{hasPath}$ e $|\mathsf{outDegree}| = 1$}
        \State $\mathsf{path} \gets$ lista com único vértice de $\mathsf{outDegree}$
        \State \Return $(\mathsf{path}, \mathsf{verdadeiro}, \mathsf{verdadeiro})$
    \EndIf
    
    \State $\mathsf{stack} \gets \emptyset$
    \State $\mathsf{path} \gets \emptyset$
    \State $\mathsf{workGraph} \gets$ cópia de $G$
    \State $u \gets v_0$
    
    \While{$\mathsf{stack} \neq \emptyset$ \textbf{ou} $\mathsf{workGraph.vizinhos}(u) \neq \emptyset$}
        \If{$\mathsf{workGraph.vizinhos}(u) \neq \emptyset$}
            \State empilhar($\mathsf{stack}$, $u$)
            \State $v \gets$ primeiro vizinho de $u$ em $\mathsf{workGraph}$
            \If{$\texttt{is\_directed}$}
                \State $\mathsf{workGraph.removerAresta}(u, v)$
            \Else
                \State $\mathsf{workGraph.removerArestaNaoDirecionada}(u, v)$
            \EndIf
            \State $u \gets v$
        \Else
            \State adicionar $u$ a $\mathsf{path}$
            \State $u \gets$ desempilhar($\mathsf{stack}$)
            \If{$\mathsf{stack} = \emptyset$}
                \State adicionar $u$ a $\mathsf{path}$
            \EndIf
        \EndIf
    \EndWhile
    
    \State inverter $\mathsf{path}$
    
    \State $\mathsf{totalArestas} \gets$ \Call{ContarArestas}{$G$, $\texttt{is\_directed}$}
    \State $\mathsf{caminhoValido} \gets (|\mathsf{path}| = \mathsf{totalArestas} + 1)$
    
    \State \Return $(\mathsf{path}, \mathsf{hasCycle} \ \mathbf{e} \ \mathsf{caminhoValido}, \mathsf{hasPath} \ \mathbf{e} \ \mathsf{caminhoValido})$
\EndFunction
\end{algorithmic}
\end{algorithm}
% tex-fmt: on
